{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "computational-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideas\n",
    "#types of steps, length of steps, types of ingredients length of ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "committed-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_LEN = 6\n",
    "\n",
    "def read_data(file):\n",
    "    df = pd.read_csv(file) \n",
    "    X = []\n",
    "    y = []\n",
    "    if df.shape[1] == CSV_LEN:\n",
    "        y = df.loc[:, 'duration_label']\n",
    "        X = df.iloc[:,:CSV_LEN-1]\n",
    "    else:\n",
    "        X = df.iloc[:,:CSV_LEN-1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "failing-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data('recipe_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "roman-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class model1:\n",
    "    def __init__(self):\n",
    "        self.model =  DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        mod_X = np.array([X.loc[:,'n_steps']*X.loc[:,'n_ingredients']]).transpose()\n",
    "        self.model.fit(mod_X,y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        mod_x = x['n_steps']*x['n_ingredients']\n",
    "        return self.model.predict(mod_x,y)\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        mod_X = np.array([X.loc[:,'n_steps']*X.loc[:,'n_ingredients']]).transpose()\n",
    "        return self.model.score(mod_X,y)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painful-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.641"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model1()\n",
    "model.fit(X,y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "removable-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class model2:\n",
    "    def __init__(self):\n",
    "        self.model =  DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        mod_X = X.loc[:,['n_steps','n_ingredients']]\n",
    "        self.model.fit(mod_X,y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        mod_x = x[['n_steps','n_ingredients']]\n",
    "        return self.model.predict(mod_x,y)\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        mod_X = X.loc[:,['n_steps','n_ingredients']]\n",
    "        return self.model.score(mod_X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frank-debut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model2()\n",
    "model.fit(X,y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "voluntary-lightweight",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter doc_words of infer_vector() must be a list of strings (not a single string).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9b5a853977bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgenmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36minfer_vector\u001b[0;34m(self, doc_words, alpha, min_alpha, epochs, steps)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \"\"\"\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a common mistake; fail with a nicer error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parameter doc_words of infer_vector() must be a list of strings (not a single string).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Parameter doc_words of infer_vector() must be a list of strings (not a single string)."
     ]
    }
   ],
   "source": [
    "genmodel = gensim.models.doc2vec.Doc2Vec(vector_size=3, min_count=1, epochs=40)\n",
    "corpus_namet = X.iloc[[0,100]]['name']\n",
    "corpus_name=list(tokenize_corpus(corpus_namet))\n",
    "genmodel.build_vocab(corpus_name)\n",
    "genmodel.train(corpus_name, total_examples=genmodel.corpus_count, epochs=genmodel.epochs)\n",
    "genmodel.infer_vector(X.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cross-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec provided code\n",
    "import gensim\n",
    "\n",
    "# function to preprocess and tokenize text\n",
    "def tokenize_corpus(txt, tokens_only=False):\n",
    "    for i, line in enumerate(txt):\n",
    "        tokens = gensim.utils.simple_preprocess(line)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "random-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.498225"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doc2vec provided code\n",
    "import gensim\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "class model3:\n",
    "    def __init__(self):\n",
    "        self.vec_size = 5\n",
    "        self.dtmodel =  DecisionTreeClassifier(random_state=0)\n",
    "        self.genmodel = gensim.models.doc2vec.Doc2Vec(vector_size=self.vec_size, min_count=1, epochs=40)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        train_corpus_name = X['name']\n",
    "        test_name = X['name']\n",
    "\n",
    "        # tokenize a training corpus\n",
    "        corpus_name = list(tokenize_corpus(train_corpus_name))\n",
    "        \n",
    "        # train doc2vec on the training corpus\n",
    "        self.genmodel.build_vocab(corpus_name)\n",
    "        self.genmodel.train(corpus_name, total_examples=self.genmodel.corpus_count, epochs=self.genmodel.epochs)\n",
    "\n",
    "        # tokenize new documents\n",
    "        doc = list(tokenize_corpus(test_name, tokens_only=True))\n",
    "        # generate embeddings for the new documents\n",
    "        x_test_name = np.zeros((len(doc),self.vec_size))\n",
    "        for i in range(len(doc)):\n",
    "            x_test_name[i,:] = self.genmodel.infer_vector(doc[i])\n",
    "        self.dtmodel.fit(x_test_name,y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        doc = list(tokenize_corpus(x['name'], tokens_only=True))\n",
    "        x_test_name = np.zeros((1,self.vec_size))\n",
    "        x_test_name[0,:] = self.genmodel.infer_vector(doc[0])\n",
    "        return self.dtmodel.predict(x_test_name)[0]\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        doc = list(tokenize_corpus(X['name'], tokens_only=True))\n",
    "        x_test_name = np.zeros((len(doc),self.vec_size))\n",
    "        for i in range(len(doc)):\n",
    "            x_test_name[i,:] = self.genmodel.infer_vector(doc[i])\n",
    "        return self.dtmodel.score(x_test_name,y)\n",
    "    \n",
    "model =  model3()\n",
    "model.fit(X,y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "radio-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(model):\n",
    "    test = pd.read_csv(recipie_test.csv) \n",
    "    X, y = read_data(test)\n",
    "    f = open('output.csv', 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id','duration_label'])\n",
    "    for i, row in enumerate(X):\n",
    "        writer.writerow([i,model.predict(X)[0]])\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "rocky-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object tokenize_corpus at 0x1247e8b10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_corpus(X.loc[0]['name'], tokens_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-third",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
