{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "characteristic-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideas\n",
    "#types of steps, length of steps, types of ingredients length of ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "massive-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_LEN = 6\n",
    "\n",
    "def read_data(file):\n",
    "    df = pd.read_csv(file) \n",
    "    X = []\n",
    "    y = []\n",
    "    if df.shape[1] == CSV_LEN:\n",
    "        y = df.loc[:, 'duration_label']\n",
    "        X = df.iloc[:,:CSV_LEN-1]\n",
    "    else:\n",
    "        X = df.iloc[:,:CSV_LEN-1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "established-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data('recipe_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "desperate-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class model1:\n",
    "    def __init__(self):\n",
    "        self.model = SVC(gamma=2, C=1)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        mod_X = X.loc[:,['n_steps','n_ingredients']]\n",
    "        self.model.fit(mod_X,y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        mod_x = x[['n_steps','n_ingredients']]\n",
    "        return self.model.predict(mod_x.values.reshape(1, -1))[0]\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        mod_X = X.loc[:,['n_steps','n_ingredients']]\n",
    "        return self.model.score(mod_X,y)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "solid-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64405\n",
      "15618.083697454998\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "toc = time.perf_counter()\n",
    "model = model1()\n",
    "model.fit(X,y)\n",
    "model.score(X,y)\n",
    "print(0.64405)\n",
    "toc = time.perf_counter()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "simplified-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class model2:\n",
    "    def __init__(self):\n",
    "        self.model =  DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        mod_X = X.loc[:,['n_steps','n_ingredients']]\n",
    "        self.model.fit(mod_X,y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        mod_x = x[['n_steps','n_ingredients']]\n",
    "        return self.model.predict(mod_x.values.reshape(1, -1))[0]\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        mod_X = X.loc[:,['n_steps','n_ingredients']]\n",
    "        return self.model.score(mod_X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "compatible-pierre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04944610700113117\n",
      "0.644125\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "model = model2() \n",
    "model.fit(X,y)\n",
    "model.score(X,y)\n",
    "toc = time.perf_counter()\n",
    "print(toc-tic)\n",
    "print(0.644125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "patient-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_name = X.loc[0:10,['name', 'steps','ingredients']]\n",
    "corpus_name = list(tokenize_corpus(train_corpus_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "valued-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec provided code\n",
    "import gensim\n",
    "import ast\n",
    "# function to preprocess and tokenize text\n",
    "def tokenize_corpus(txt, tokens_only=False):\n",
    "    if txt.shape[0] == txt.size:\n",
    "        line = txt\n",
    "        name = line[0]\n",
    "        steps=\"\"\n",
    "        for i in ast.literal_eval(line[1]):\n",
    "            steps+= \" \"+i\n",
    "        ingeredients=\"\"\n",
    "        for i in ast.literal_eval(line[2]):\n",
    "            ingeredients+=\" \"+i\n",
    "        row = name + \" \" + steps + \" \" + ingeredients\n",
    "        tokens = gensim.utils.simple_preprocess(row)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [line[0]])\n",
    "        return\n",
    "    for line in txt.iterrows():\n",
    "        name = line[1][0]\n",
    "        steps=\"\"\n",
    "        for i in ast.literal_eval(line[1][1]):\n",
    "            steps+= \" \"+i\n",
    "        ingeredients=\"\"\n",
    "        for i in ast.literal_eval(line[1][2]):\n",
    "            ingeredients+=\" \"+i\n",
    "        row = name + \" \" + steps + \" \" + ingeredients\n",
    "        tokens = gensim.utils.simple_preprocess(row)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [line[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "differential-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec provided code\n",
    "import gensim\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "class model3:\n",
    "    def __init__(self):\n",
    "        self.vec_size = 75\n",
    "        self.dtmodel =  DecisionTreeClassifier(random_state=0)\n",
    "        self.genmodel = gensim.models.doc2vec.Doc2Vec(vector_size=self.vec_size, min_count=1, epochs=40)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        train_corpus_name = X.loc[:,['name', 'steps','ingredients']]\n",
    "        test_name = X.loc[:,['name','steps','ingredients']]\n",
    "\n",
    "        # tokenize a training corpus\n",
    "        corpus_name = list(tokenize_corpus(train_corpus_name))\n",
    "        # train doc2vec on the training corpus\n",
    "        self.genmodel.build_vocab(corpus_name)\n",
    "        self.genmodel.train(corpus_name, total_examples=self.genmodel.corpus_count, epochs=self.genmodel.epochs)\n",
    "\n",
    "        # tokenize new documents\n",
    "        doc = list(tokenize_corpus(test_name, tokens_only=True))\n",
    "        # generate embeddings for the new documents\n",
    "        x_test_name = np.zeros((len(doc),self.vec_size))\n",
    "        for i in range(len(doc)):\n",
    "            x_test_name[i,:] = self.genmodel.infer_vector(doc[i])\n",
    "        self.dtmodel.fit(x_test_name,y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        doc = list(tokenize_corpus(x.loc[['name', 'steps','ingredients']], tokens_only=True))\n",
    "        x_test_name = np.zeros((1,self.vec_size))\n",
    "        x_test_name[0,:] = self.genmodel.infer_vector(doc[0])\n",
    "        return self.dtmodel.predict(x_test_name)[0]\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        doc = list(tokenize_corpus(X.loc[:,['name', 'steps','ingredients']], tokens_only=True))\n",
    "        x_test_name = np.zeros((len(doc),self.vec_size))\n",
    "        for i in range(len(doc)):\n",
    "            x_test_name[i,:] = self.genmodel.infer_vector(doc[i])\n",
    "        return self.dtmodel.score(x_test_name,y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dated-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_output(model):\n",
    "    test = \"recipe_test.csv\"\n",
    "    X, y = read_data(test)\n",
    "    f = open('output.csv', 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id','duration_label'])\n",
    "    #for i, row in enumerate(X.iterrows()):\n",
    "    for i in range(10000):\n",
    "        x = X.loc[i,:]\n",
    "        writer.writerow([i+1,model.predict(x)])\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "generic-shuttle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object tokenize_corpus at 0x119d56480>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_corpus(X.loc[0]['name'], tokens_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "still-individual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540.1526337899995\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tic = time.perf_counter()\n",
    "model =  model3()\n",
    "model.fit(X,y)\n",
    "#model.score(X,y)\n",
    "toc = time.perf_counter()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "honey-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(txt):\n",
    "    combined =[]\n",
    "    if txt.shape[0] == txt.size:\n",
    "        line = txt\n",
    "        name = line[0]\n",
    "        steps=\"\"\n",
    "        for i in ast.literal_eval(line[1]):\n",
    "            steps+= \" \"+i\n",
    "        ingeredients=\"\"\n",
    "        for i in ast.literal_eval(line[2]):\n",
    "            ingeredients+=\" \"+i\n",
    "        row = name + \" \" + steps + \" \" + ingeredients\n",
    "        combined.append(row)\n",
    "        return combined\n",
    "    for line in txt.iterrows():\n",
    "        name = line[1][0]\n",
    "        steps=\"\"\n",
    "        for i in ast.literal_eval(line[1][1]):\n",
    "            steps+= \" \"+i\n",
    "        ingeredients=\"\"\n",
    "        for i in ast.literal_eval(line[1][2]):\n",
    "            ingeredients+=\" \"+i\n",
    "        row = name + \" \" + steps + \" \" + ingeredients\n",
    "        combined.append(row)\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "associate-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "class model4:\n",
    "    def __init__(self):\n",
    "        self.model = SGDClassifier(max_iter = 1000, alpha = 0.001)\n",
    "        self.vocab = CountVectorizer(stop_words='english')\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        train_corpus = X.loc[:,['name', 'steps','ingredients']]\n",
    "\n",
    "        # fit the count vec\n",
    "        self.vocab.fit(combine_features(train_corpus))\n",
    "        \n",
    "        #vectorise each row\n",
    "        X_mod = self.vocab.transform(combine_features(train_corpus))\n",
    "        # fit\n",
    "        self.model.fit(X_mod,y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        row  = x.loc[['name', 'steps','ingredients']]\n",
    "        mod_x = self.vocab.transform(combine_features(row))\n",
    "        return self.model.predict(mod_x)[0]\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        data = X.loc[:,['name', 'steps','ingredients']]\n",
    "        X_mod = self.vocab.transform(combine_features(data))\n",
    "        return self.model.score(X_mod,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "offensive-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1133.6593502450014\n",
      "0.843175\n"
     ]
    }
   ],
   "source": [
    "toc = time.perf_counter()\n",
    "model = model4() \n",
    "model.fit(X,y)\n",
    "print(model.score(X,y))\n",
    "toc = time.perf_counter()\n",
    "print(toc-tic)\n",
    "print(0.843175)\n",
    "write_output(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "automated-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def random_cross_val_score(model, X, y, kfold, itter):\n",
    "    score = 0\n",
    "    for i in range(itter):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/kfold, random_state=42)\n",
    "        model.fit(X_train,y_train)\n",
    "        score += model.score(X_test,y_test)\n",
    "        print(score/(i+1))\n",
    "    return score/itter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "recognized-quilt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8015\n",
      "0.801625\n",
      "0.8000833333333334\n",
      "0.8008125\n",
      "0.80095\n",
      "0.80125\n",
      "0.8013928571428571\n",
      "0.80140625\n",
      "0.8009999999999999\n",
      "0.8006499999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8006499999999999"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cross_val_score(model, X, y, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "remarkable-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63725\n",
      "0.63725\n",
      "0.63725\n",
      "0.63725\n",
      "0.63725\n",
      "0.63725\n",
      "0.63725\n",
      "0.63725\n",
      "0.63725\n",
      "0.63725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.63725"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cross_val_score(model1(), X, y, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "controlling-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6305\n",
      "0.6305\n",
      "0.6305\n",
      "0.6305\n",
      "0.6305\n",
      "0.6305\n",
      "0.6305\n",
      "0.6305\n",
      "0.6305\n",
      "0.6304999999999998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6304999999999998"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cross_val_score(model2(), X, y, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "correct-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-southwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-forum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-gentleman",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
